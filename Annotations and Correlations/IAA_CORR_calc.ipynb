{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afeb762c-6af5-495e-a888-24bc695c452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import krippendorff\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "from utils.iaa_util import chonker, no_noise_lists, filter_noise_scores, dia_ex, sum_ex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49526f88",
   "metadata": {},
   "source": [
    "# Inter Annotator Agreement & Correlation Calculation\n",
    "\n",
    "This notebook is intended to make the calculations easy to do and gather the results within this notebook.\\\n",
    "No results are stored anywhere else on this drive.\n",
    "\n",
    "A script version for different sections of this notebook can be found in the same folder as this file:\\\n",
    "`ablation_corr.py` and `originalVpresent_iaa_corr.py`\\\n",
    "That file will store the results on the drive in csv files in the 'results' folder\n",
    "\n",
    "To run the present notebook correctly please make sure to adjust the filepaths in the cell below to adhere to the correct file names and paths. When that is set, running all cells will output the results in the various sections of this file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6983613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths\n",
    "# Ablation results\n",
    "ann1_ablation_path = 'data/ablation_ann1.xlsx'\n",
    "ann2_ablation_path = 'data/ablation_ann2.xlsx'\n",
    "ann3_ablation_path = 'data/ablation_ann3.xlsx'\n",
    "\n",
    "# Full results\n",
    "ann1_results_path = f'data/saved_df_ann1.csv'\n",
    "ann2_results_path = f'data/saved_df_ann2.csv'\n",
    "ann3_results_path = f'data/saved_df_ann3.csv'\n",
    "\n",
    "# Original paper results\n",
    "original_results_path = 'data/original_human_judgment.jsonl'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13bd8270",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b361266-8eb5-4ce8-af11-c919cb262437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present paper data\n",
    "ann1 = pd.read_csv(ann1_results_path, delimiter=';')\n",
    "ann2 = pd.read_csv(ann2_results_path, delimiter=';')\n",
    "ann3 = pd.read_csv(ann3_results_path, delimiter=';')\n",
    "\n",
    "# original data\n",
    "fname = original_results_path\n",
    "data = [] #NEWstart\n",
    "with open(fname, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line.rstrip('\\n|\\r')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fab5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform original data to match our data\n",
    "original_annotator_scores= []\n",
    "\n",
    "# a row in the data: id, dialogue, summary, annotations, model_id\n",
    "# loop through annotator and each dimension \n",
    "for annotator in [0,1,2]:  \n",
    "    scores = []  \n",
    "    for type in ['consistency', 'coherence', 'fluency', 'relevance']:\n",
    "        list_annotations=[]\n",
    "        # store all annotations for an annotator \n",
    "        for row in data:\n",
    "            annotations = row.get('annotations')\n",
    "            list_annotations.append(annotations[annotator])\n",
    "        dimension_list=[]\n",
    "        # \n",
    "        for dimensions in list_annotations:\n",
    "            dimension=dimensions.get(type.lower())\n",
    "            dimension_list.append(dimension)\n",
    "        scores.append(dimension_list)\n",
    "    original_annotator_scores.append(scores)\n",
    "\n",
    "orig_ann1 = pd.DataFrame(zip(original_annotator_scores[0][0], original_annotator_scores[0][1], original_annotator_scores[0][2], original_annotator_scores[0][3]), \n",
    "        columns=['consistency_results', 'coherence_results', 'fluency_results', 'relevance_results'])\n",
    "\n",
    "orig_ann2 = pd.DataFrame(zip(original_annotator_scores[1][0], original_annotator_scores[1][1], original_annotator_scores[1][2], original_annotator_scores[1][3]), \n",
    "        columns=['consistency_results', 'coherence_results', 'fluency_results', 'relevance_results'])\n",
    "\n",
    "orig_ann3 = pd.DataFrame(zip(original_annotator_scores[2][0], original_annotator_scores[2][1], original_annotator_scores[2][2], original_annotator_scores[2][3]), \n",
    "        columns=['consistency_results', 'coherence_results', 'fluency_results', 'relevance_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb5e0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation data\n",
    "tab_names = ['A', 'B', 'C', 'D', 'E' ,'F', 'G' ,'H' ,'I','J' ,'K', 'L', 'M' , 'N']\n",
    "df_1 = pd.concat(pd.read_excel(ann1_ablation_path, sheet_name=tab_names))\n",
    "df_2 = pd.concat(pd.read_excel(ann2_ablation_path, sheet_name=tab_names))\n",
    "df_3 = pd.concat(pd.read_excel(ann3_ablation_path, sheet_name=tab_names))\n",
    "\n",
    "# The full data has its text displayed differently from the ablation data\n",
    "# The following code aligns this:\n",
    "for df in [ann1, ann2, ann3]:\n",
    "    df['dialogue'] = df.texts.transform(dia_ex)\n",
    "    df['summary'] = df.texts.transform(sum_ex)\n",
    "\n",
    "# extract dialogues from full\n",
    "ann1_selection = ann1[ann1['summary'].isin(list(df_1['summary']))]\n",
    "ann2_selection = ann2[ann2['summary'].isin(list(df_2['summary']))]\n",
    "ann3_selection = ann3[ann3['summary'].isin(list(df_3['summary']))]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b59dbb84",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "Set up variables to do IAA and correlations.\\\n",
    "This section does the following:\n",
    "1. Split every dimension's results into nested lists of 14 scores (1 list per dialogue). \n",
    "2. replace noisy scores by `np.nan` (see paper for a discussion)\n",
    "3. Calculate an averaged score for each summary. Results in an array of (100, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a31fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. \n",
    "# Present paper annotations\n",
    "# transform the list of evaluation values into: [[n*14]*100]\n",
    "coherence_ann1 = chonker(list(ann1['coherence_results']), 14)\n",
    "coherence_ann2 = chonker(list(ann2['coherence_results']), 14)\n",
    "coherence_ann3 = chonker(list(ann3['coherence_results']), 14)\n",
    "\n",
    "consistency_ann1 = chonker(list(ann1['consistency_results']), 14)\n",
    "consistency_ann2 = chonker(list(ann2['consistency_results']), 14)\n",
    "consistency_ann3 = chonker(list(ann3['consistency_results']), 14)\n",
    "\n",
    "fluency_ann1 = chonker(list(ann1['fluency_results']), 14)\n",
    "fluency_ann2 = chonker(list(ann2['fluency_results']), 14)\n",
    "fluency_ann3 = chonker(list(ann3['fluency_results']), 14)\n",
    "\n",
    "relevance_ann1 = chonker(list(ann1['relevance_results']), 14)\n",
    "relevance_ann2 = chonker(list(ann2['relevance_results']), 14)\n",
    "relevance_ann3 = chonker(list(ann3['relevance_results']), 14)\n",
    "\n",
    "# Original Annotators\n",
    "# transform the list of evaluation values into: [[n*14]*100]\n",
    "coherence_orig_ann1 = chonker(list(orig_ann1['coherence_results']), 14)\n",
    "coherence_orig_ann2 = chonker(list(orig_ann2['coherence_results']), 14)\n",
    "coherence_orig_ann3 = chonker(list(orig_ann3['coherence_results']), 14)\n",
    "\n",
    "consistency_orig_ann1 = chonker(list(orig_ann1['consistency_results']), 14)\n",
    "consistency_orig_ann2 = chonker(list(orig_ann2['consistency_results']), 14)\n",
    "consistency_orig_ann3 = chonker(list(orig_ann3['consistency_results']), 14)\n",
    "\n",
    "fluency_orig_ann1 = chonker(list(orig_ann1['fluency_results']), 14)\n",
    "fluency_orig_ann2 = chonker(list(orig_ann2['fluency_results']), 14)\n",
    "fluency_orig_ann3 = chonker(list(orig_ann3['fluency_results']), 14)\n",
    "\n",
    "relevance_orig_ann1 = chonker(list(orig_ann1['relevance_results']), 14)\n",
    "relevance_orig_ann2 = chonker(list(orig_ann2['relevance_results']), 14)\n",
    "relevance_orig_ann3 = chonker(list(orig_ann3['relevance_results']), 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828f6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. \n",
    "# Do the same as the cell before, but for all the ablation data\n",
    "# Our full annotation (but selection)\n",
    "# transform the list of evaluation values into: [[n*14]*10]\n",
    "coherence_ann1_sel = chonker(list(ann1_selection['coherence_results']), 14)\n",
    "coherence_ann2_sel = chonker(list(ann2_selection['coherence_results']), 14)\n",
    "coherence_ann3_sel = chonker(list(ann3_selection['coherence_results']), 14)\n",
    "\n",
    "consistency_ann1_sel = chonker(list(ann1_selection['consistency_results']), 14)\n",
    "consistency_ann2_sel = chonker(list(ann2_selection['consistency_results']), 14)\n",
    "consistency_ann3_sel = chonker(list(ann3_selection['consistency_results']), 14)\n",
    "\n",
    "fluency_ann1_sel = chonker(list(ann1_selection['fluency_results']), 14)\n",
    "fluency_ann2_sel = chonker(list(ann2_selection['fluency_results']), 14)\n",
    "fluency_ann3_sel = chonker(list(ann3_selection['fluency_results']), 14)\n",
    "\n",
    "relevance_ann1_sel = chonker(list(ann1_selection['relevance_results']), 14)\n",
    "relevance_ann2_sel = chonker(list(ann2_selection['relevance_results']), 14)\n",
    "relevance_ann3_sel = chonker(list(ann3_selection['relevance_results']), 14)\n",
    "\n",
    "\n",
    "# new ablation\n",
    "# transform the list of evaluation values into: [[n*14]*10]\n",
    "coherence_ann1_abl = [[item[i] for item in chonker(list(df_1['Coherence']), 10)] for i in range(10)]\n",
    "coherence_ann2_abl = [[item[i] for item in chonker(list(df_2['Coherence']), 10)] for i in range(10)]\n",
    "coherence_ann3_abl = [[item[i] for item in chonker(list(df_3['Coherence']), 10)] for i in range(10)]\n",
    "\n",
    "consistency_ann1_abl = [[item[i] for item in chonker(list(df_1['Consistency']), 10)] for i in range(10)]\n",
    "consistency_ann2_abl = [[item[i] for item in chonker(list(df_2['Consistency']), 10)] for i in range(10)]\n",
    "consistency_ann3_abl = [[item[i] for item in chonker(list(df_3['Consistency']), 10)] for i in range(10)]\n",
    "\n",
    "fluency_ann1_abl = [[item[i] for item in chonker(list(df_1['Fluency']), 10)] for i in range(10)]\n",
    "fluency_ann2_abl = [[item[i] for item in chonker(list(df_2['Fluency']), 10)] for i in range(10)]\n",
    "fluency_ann3_abl = [[item[i] for item in chonker(list(df_3['Fluency']), 10)] for i in range(10)]\n",
    "\n",
    "relevance_ann1_abl = [[item[i] for item in chonker(list(df_1['Relevance']), 10)] for i in range(10)]\n",
    "relevance_ann2_abl = [[item[i] for item in chonker(list(df_2['Relevance']), 10)] for i in range(10)]\n",
    "relevance_ann3_abl = [[item[i] for item in chonker(list(df_3['Relevance']), 10)] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad5ec825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores that were not filtered: 3161\n",
      "Number of scores that were not filtered: 3360\n",
      "Number of scores that were not filtered: 3050\n",
      "Number of scores that were not filtered: 3439\n"
     ]
    }
   ],
   "source": [
    "# 2. \n",
    "# Noise replacement\n",
    "orig_coherence_nonoise1, orig_coherence_nonoise2, orig_coherence_nonoise3 = no_noise_lists(coherence_orig_ann1, coherence_orig_ann2, coherence_orig_ann3)\n",
    "orig_consistency_nonoise1, orig_consistency_nonoise2, orig_consistency_nonoise3 = no_noise_lists(consistency_orig_ann1, consistency_orig_ann2, consistency_orig_ann3)\n",
    "orig_fluency_nonoise1, orig_fluency_nonoise2, orig_fluency_nonoise3 = no_noise_lists(fluency_orig_ann1, fluency_orig_ann2, fluency_orig_ann3)\n",
    "orig_relevance_nonoise1, orig_relevance_nonoise2, orig_relevance_nonoise3 = no_noise_lists(relevance_orig_ann1, relevance_orig_ann2, relevance_orig_ann3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca6c4b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores that were not filtered: 3607\n",
      "Number of scores that were not filtered: 3754\n",
      "Number of scores that were not filtered: 3625\n",
      "Number of scores that were not filtered: 3394\n"
     ]
    }
   ],
   "source": [
    "coherence_nonoise1, coherence_nonoise2, coherence_nonoise3 = no_noise_lists(coherence_ann1, coherence_ann2, coherence_ann3)\n",
    "consistency_nonoise1,consistency_nonoise2,consistency_nonoise3 = no_noise_lists(consistency_ann1, consistency_ann2, consistency_ann3)\n",
    "fluency_nonoise1, fluency_nonoise2,fluency_nonoise3 = no_noise_lists(fluency_ann1, fluency_ann2, fluency_ann3)\n",
    "relevance_nonoise1,relevance_nonoise2,relevance_nonoise3 = no_noise_lists(relevance_ann1, relevance_ann2, relevance_ann3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a40351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "# for each dimension filer out the noise and take the average\n",
    "# our results\n",
    "coherence_filtered = filter_noise_scores(coherence_ann1, coherence_ann2, coherence_ann3, 100)\n",
    "consistency_filtered = filter_noise_scores(consistency_ann1, consistency_ann2, consistency_ann3, 100)\n",
    "fluency_filtered = filter_noise_scores(fluency_ann1, fluency_ann2, fluency_ann3, 100)\n",
    "relevance_filtered = filter_noise_scores(relevance_ann1, relevance_ann2, relevance_ann3, 100) \n",
    "\n",
    "# original results\n",
    "orig_coherence_filtered = filter_noise_scores(coherence_orig_ann1, coherence_orig_ann2, coherence_orig_ann3, 100)\n",
    "orig_consistency_filtered = filter_noise_scores(consistency_orig_ann1, consistency_orig_ann2, consistency_orig_ann3, 100)\n",
    "orig_fluency_filtered = filter_noise_scores(fluency_orig_ann1, fluency_orig_ann2, fluency_orig_ann3, 100)\n",
    "orig_relevance_filtered = filter_noise_scores(relevance_orig_ann1, relevance_orig_ann2, relevance_orig_ann3, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a500705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. \n",
    "# same as above but for ablation data\n",
    "coherence_filtered_sel = filter_noise_scores(coherence_ann1_sel, coherence_ann2_sel, coherence_ann3_sel, 10)\n",
    "consistency_filtered_sel = filter_noise_scores(consistency_ann1_sel, consistency_ann2_sel, consistency_ann3_sel, 10)\n",
    "fluency_filtered_sel = filter_noise_scores(fluency_ann1_sel, fluency_ann2_sel, fluency_ann3_sel, 10)\n",
    "relevance_filtered_sel = filter_noise_scores(relevance_ann1_sel, relevance_ann2_sel, relevance_ann3_sel, 10) \n",
    "\n",
    "coherence_filtered_abl = filter_noise_scores(coherence_ann1_abl, coherence_ann2_abl, coherence_ann3_abl, 10)\n",
    "consistency_filtered_abl = filter_noise_scores(consistency_ann1_abl, consistency_ann2_abl, consistency_ann3_abl, 10)\n",
    "fluency_filtered_abl = filter_noise_scores(fluency_ann1_abl, fluency_ann2_abl, fluency_ann3_abl, 10)\n",
    "relevance_filtered_abl = filter_noise_scores(relevance_ann1_abl, relevance_ann2_abl, relevance_ann3_abl, 10) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16a5116d",
   "metadata": {},
   "source": [
    "# calculations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc9e20b0",
   "metadata": {},
   "source": [
    "### IAA calculations\n",
    "Using krippendorff's alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc44a257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original IAA scores:\n",
      "Coherence: 0.3785576910327453 \n",
      "Consistency: 0.492762621233651 \n",
      "Fluency: 0.13361325787541334 \n",
      "Relevance: 0.38671951755027045\n"
     ]
    }
   ],
   "source": [
    "# Original IAA\n",
    "coherence_IAA = krippendorff.alpha(reliability_data=[list(orig_ann1['coherence_results']),list(orig_ann2['coherence_results']),list(orig_ann3['coherence_results'])], level_of_measurement=\"interval\")\n",
    "fluency_IAA = krippendorff.alpha(reliability_data=[list(orig_ann1['fluency_results']),list(orig_ann2['fluency_results']),list(orig_ann3['fluency_results'])],level_of_measurement=\"interval\")\n",
    "consistency_IAA = krippendorff.alpha(reliability_data=[list(orig_ann1['consistency_results']),list(orig_ann2['consistency_results']),list(orig_ann3['consistency_results'])],level_of_measurement=\"interval\")\n",
    "relevance_IAA = krippendorff.alpha(reliability_data=[list(orig_ann1['relevance_results']),list(orig_ann2['relevance_results']),list(orig_ann3['relevance_results'])],level_of_measurement=\"interval\")\n",
    "\n",
    "print(f'Original IAA scores:\\nCoherence: {coherence_IAA} \\nConsistency: {consistency_IAA} \\nFluency: {fluency_IAA} \\nRelevance: {relevance_IAA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36d58658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original IAA scores (cleaned):\n",
      "Coherence: 0.7564020052749023 \n",
      "Consistency: 0.6709247287723659 \n",
      "Fluency: 0.6781873766563293 \n",
      "Relevance: 0.5620838662718799\n"
     ]
    }
   ],
   "source": [
    "coherence_IAA = krippendorff.alpha(reliability_data=[orig_coherence_nonoise1, orig_coherence_nonoise2, orig_coherence_nonoise3], level_of_measurement=\"interval\")\n",
    "fluency_IAA = krippendorff.alpha(reliability_data=[orig_fluency_nonoise1, orig_fluency_nonoise2, orig_fluency_nonoise3],level_of_measurement=\"interval\")\n",
    "consistency_IAA = krippendorff.alpha(reliability_data=[orig_consistency_nonoise1, orig_consistency_nonoise2, orig_consistency_nonoise3],level_of_measurement=\"interval\")\n",
    "relevance_IAA = krippendorff.alpha(reliability_data=[orig_relevance_nonoise1, orig_relevance_nonoise2, orig_relevance_nonoise3],level_of_measurement=\"interval\")\n",
    "\n",
    "print(f'Original IAA scores (cleaned):\\nCoherence: {coherence_IAA} \\nConsistency: {consistency_IAA} \\nFluency: {fluency_IAA} \\nRelevance: {relevance_IAA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efab3a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our IAA scores:\n",
      "Coherence: 0.6074598852525589 \n",
      "Consistency: 0.7938139086383895 \n",
      "Fluency: 0.5233497800176004 \n",
      "Relevance: 0.5159398644189812\n"
     ]
    }
   ],
   "source": [
    "# Our IAA\n",
    "coherence_IAA = krippendorff.alpha(reliability_data=[list(ann1['coherence_results']),list(ann2['coherence_results']),list(ann3['coherence_results'])], level_of_measurement=\"interval\")\n",
    "fluency_IAA = krippendorff.alpha(reliability_data=[list(ann1['fluency_results']),list(ann2['fluency_results']),list(ann3['fluency_results'])],level_of_measurement=\"interval\")\n",
    "consistency_IAA = krippendorff.alpha(reliability_data=[list(ann1['consistency_results']),list(ann2['consistency_results']),list(ann3['consistency_results'])],level_of_measurement=\"interval\")\n",
    "relevance_IAA = krippendorff.alpha(reliability_data=[list(ann1['relevance_results']),list(ann2['relevance_results']),list(ann3['relevance_results'])],level_of_measurement=\"interval\")\n",
    "\n",
    "print(f'Our IAA scores:\\nCoherence: {coherence_IAA} \\nConsistency: {consistency_IAA} \\nFluency: {fluency_IAA} \\nRelevance: {relevance_IAA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e37d9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our IAA scores (cleaned):\n",
      "Coherence: 0.7780447258554797 \n",
      "Consistency: 0.9227800328928509 \n",
      "Fluency: 0.76903271937251 \n",
      "Relevance: 0.7160557952595286\n"
     ]
    }
   ],
   "source": [
    "coherence_IAA = krippendorff.alpha(reliability_data=[coherence_nonoise1, coherence_nonoise2, coherence_nonoise3], level_of_measurement=\"interval\")\n",
    "fluency_IAA = krippendorff.alpha(reliability_data=[fluency_nonoise1, fluency_nonoise2, fluency_nonoise3],level_of_measurement=\"interval\")\n",
    "consistency_IAA = krippendorff.alpha(reliability_data=[consistency_nonoise1, consistency_nonoise2, consistency_nonoise3],level_of_measurement=\"interval\")\n",
    "relevance_IAA = krippendorff.alpha(reliability_data=[relevance_nonoise1, relevance_nonoise2, relevance_nonoise3],level_of_measurement=\"interval\")\n",
    "\n",
    "print(f'Our IAA scores (cleaned):\\nCoherence: {coherence_IAA} \\nConsistency: {consistency_IAA} \\nFluency: {fluency_IAA} \\nRelevance: {relevance_IAA}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1eb1582a",
   "metadata": {},
   "source": [
    "### Correlation between original paper annotations and present paper's\n",
    "using Pearson's R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98e7fe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence correlation 0.417\n",
      "Consistency correlation 0.77\n",
      "Fluency correlation 0.546\n",
      "Relevance correlation 0.685\n"
     ]
    }
   ],
   "source": [
    "# first transform filtered arrays into a single long list\n",
    "# for each dimension, for both present paper and original results\n",
    "list_coh_fil = list(itertools.chain(*coherence_filtered))\n",
    "list_coh_fil_orig = list(itertools.chain(*orig_coherence_filtered))\n",
    "\n",
    "list_con_fil = list(itertools.chain(*consistency_filtered))\n",
    "list_con_fil_orig = list(itertools.chain(*orig_consistency_filtered))\n",
    "\n",
    "list_flu_fil = list(itertools.chain(*fluency_filtered))\n",
    "list_flu_fil_orig = list(itertools.chain(*orig_fluency_filtered))\n",
    "\n",
    "list_rel_fil = list(itertools.chain(*relevance_filtered))\n",
    "list_rel_fil_orig = list(itertools.chain(*orig_relevance_filtered))\n",
    "\n",
    "print('Coherence correlation', round(np.corrcoef(list_coh_fil, list_coh_fil_orig)[0][1],3))\n",
    "print('Consistency correlation', round(np.corrcoef(list_con_fil, list_con_fil_orig)[0][1],3))\n",
    "print('Fluency correlation', round(np.corrcoef(list_flu_fil, list_flu_fil_orig)[0][1],3))\n",
    "print('Relevance correlation', round(np.corrcoef(list_rel_fil, list_rel_fil_orig)[0][1],3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e8c7f89",
   "metadata": {},
   "source": [
    "### Ablation study Correlation\n",
    "Using Pearson's R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5800de59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence correlation 0.705\n",
      "Consistency correlation 0.664\n",
      "Fluency correlation 0.767\n",
      "Relevance correlation 0.51\n"
     ]
    }
   ],
   "source": [
    "list_coh_fil = list(itertools.chain(*coherence_filtered_sel))\n",
    "list_coh_fil_orig = list(itertools.chain(*coherence_filtered_abl))\n",
    "list_con_fil = list(itertools.chain(*consistency_filtered_sel))\n",
    "list_con_fil_orig = list(itertools.chain(*consistency_filtered_abl))\n",
    "list_flu_fil = list(itertools.chain(*fluency_filtered_sel))\n",
    "list_flu_fil_orig = list(itertools.chain(*fluency_filtered_abl))\n",
    "list_rel_fil = list(itertools.chain(*relevance_filtered_sel))\n",
    "list_rel_fil_orig = list(itertools.chain(*relevance_filtered_abl))\n",
    "\n",
    "print('Coherence correlation', round(np.corrcoef(list_coh_fil, list_coh_fil_orig)[0][1],3))\n",
    "print('Consistency correlation', round(np.corrcoef(list_con_fil, list_con_fil_orig)[0][1],3))\n",
    "print('Fluency correlation', round(np.corrcoef(list_flu_fil, list_flu_fil_orig)[0][1],3))\n",
    "print('Relevance correlation', round(np.corrcoef(list_rel_fil, list_rel_fil_orig)[0][1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc54e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6f88519aa74d89c62cdcc59414067e256965681425d9b4dee1ef762f1172e6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
