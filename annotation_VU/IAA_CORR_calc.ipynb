{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afeb762c-6af5-495e-a888-24bc695c452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import krippendorff\n",
    "import json\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69bc3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mojca= pd.read_csv(f'C:\\\\Users\\\\patri\\\\Desktop\\\\University\\\\AI\\\\combots\\\\Results-20221216T235732Z-001\\\\Results\\\\saved_df_mojca.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3ee038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1.1.1.1</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1.1.1.1.1.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1.1.1.1.1.1.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1</th>\n",
       "      <th>texts</th>\n",
       "      <th>coherence_results</th>\n",
       "      <th>consistency_results</th>\n",
       "      <th>relevance_results</th>\n",
       "      <th>fluency_results</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;br&gt;&lt;br&gt; Elena: Happy birthday my dear! &lt;br&gt;&lt;b...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;br&gt;&lt;br&gt; Elena: Happy birthday my dear! &lt;br&gt;&lt;b...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Just takes sentences from the original dialogu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;br&gt;&lt;br&gt; Elena: Happy birthday my dear! &lt;br&gt;&lt;b...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Does not capture some of the facts that are in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;br&gt;&lt;br&gt; Elena: Happy birthday my dear! &lt;br&gt;&lt;b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Not true, doesnt capture any of the importantt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;br&gt;&lt;br&gt; Elena: Happy birthday my dear! &lt;br&gt;&lt;b...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Not true fact, doesnt capture other important ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>...</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>&lt;br&gt;&lt;br&gt; Karen: I passed!!!!! &lt;br&gt;&lt;br&gt; Simon: ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Any comments?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>...</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>&lt;br&gt;&lt;br&gt; Karen: I passed!!!!! &lt;br&gt;&lt;br&gt; Simon: ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Any comments?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>...</td>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>1397</td>\n",
       "      <td>&lt;br&gt;&lt;br&gt; Karen: I passed!!!!! &lt;br&gt;&lt;br&gt; Simon: ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Any comments?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>...</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>1398</td>\n",
       "      <td>&lt;br&gt;&lt;br&gt; Karen: I passed!!!!! &lt;br&gt;&lt;br&gt; Simon: ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Any comments?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>...</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>1399</td>\n",
       "      <td>&lt;br&gt;&lt;br&gt; Karen: I passed!!!!! &lt;br&gt;&lt;br&gt; Simon: ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Any comments?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.2  Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  \\\n",
       "0                0           0             0               0   \n",
       "1                1           1             1               1   \n",
       "2                2           2             2               2   \n",
       "3                3           3             3               3   \n",
       "4                4           4             4               4   \n",
       "...            ...         ...           ...             ...   \n",
       "1395          1395        1395          1395            1395   \n",
       "1396          1396        1396          1396            1396   \n",
       "1397          1397        1397          1397            1397   \n",
       "1398          1398        1398          1398            1398   \n",
       "1399          1399        1399          1399            1399   \n",
       "\n",
       "      Unnamed: 0.1.1.1  Unnamed: 0.1.1.1.1  Unnamed: 0.1.1.1.1.1  \\\n",
       "0                    0                   0                     0   \n",
       "1                    1                   1                     1   \n",
       "2                    2                   2                     2   \n",
       "3                    3                   3                     3   \n",
       "4                    4                   4                     4   \n",
       "...                ...                 ...                   ...   \n",
       "1395              1395                1395                  1395   \n",
       "1396              1396                1396                  1396   \n",
       "1397              1397                1397                  1397   \n",
       "1398              1398                1398                  1398   \n",
       "1399              1399                1399                  1399   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1.1.1  Unnamed: 0.1.1.1.1.1.1.1  \\\n",
       "0                          0                         0   \n",
       "1                          1                         1   \n",
       "2                          2                         2   \n",
       "3                          3                         3   \n",
       "4                          4                         4   \n",
       "...                      ...                       ...   \n",
       "1395                    1395                      1395   \n",
       "1396                    1396                      1396   \n",
       "1397                    1397                      1397   \n",
       "1398                    1398                      1398   \n",
       "1399                    1399                      1399   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1.1.1.1.1  ...  Unnamed: 0.1.1.1.1.1.1.1.1.1.1.1.1.1  \\\n",
       "0                              0  ...                                     0   \n",
       "1                              1  ...                                     1   \n",
       "2                              2  ...                                     2   \n",
       "3                              3  ...                                     3   \n",
       "4                              4  ...                                     4   \n",
       "...                          ...  ...                                   ...   \n",
       "1395                        1395  ...                                  1395   \n",
       "1396                        1396  ...                                  1396   \n",
       "1397                        1397  ...                                  1397   \n",
       "1398                        1398  ...                                  1398   \n",
       "1399                        1399  ...                                  1399   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1.1.1.1.1.1.1.1.1.1.1  \\\n",
       "0                                          0   \n",
       "1                                          1   \n",
       "2                                          2   \n",
       "3                                          3   \n",
       "4                                          4   \n",
       "...                                      ...   \n",
       "1395                                    1395   \n",
       "1396                                    1396   \n",
       "1397                                    1397   \n",
       "1398                                    1398   \n",
       "1399                                    1399   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1  \\\n",
       "0                                            0   \n",
       "1                                            1   \n",
       "2                                            2   \n",
       "3                                            3   \n",
       "4                                            4   \n",
       "...                                        ...   \n",
       "1395                                      1395   \n",
       "1396                                      1396   \n",
       "1397                                      1397   \n",
       "1398                                      1398   \n",
       "1399                                      1399   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1  \\\n",
       "0                                              0   \n",
       "1                                              1   \n",
       "2                                              2   \n",
       "3                                              3   \n",
       "4                                              4   \n",
       "...                                          ...   \n",
       "1395                                        1395   \n",
       "1396                                        1396   \n",
       "1397                                        1397   \n",
       "1398                                        1398   \n",
       "1399                                        1399   \n",
       "\n",
       "                                                  texts  coherence_results  \\\n",
       "0     <br><br> Elena: Happy birthday my dear! <br><b...                  5   \n",
       "1     <br><br> Elena: Happy birthday my dear! <br><b...                  1   \n",
       "2     <br><br> Elena: Happy birthday my dear! <br><b...                  4   \n",
       "3     <br><br> Elena: Happy birthday my dear! <br><b...                  1   \n",
       "4     <br><br> Elena: Happy birthday my dear! <br><b...                  3   \n",
       "...                                                 ...                ...   \n",
       "1395  <br><br> Karen: I passed!!!!! <br><br> Simon: ...                  5   \n",
       "1396  <br><br> Karen: I passed!!!!! <br><br> Simon: ...                  4   \n",
       "1397  <br><br> Karen: I passed!!!!! <br><br> Simon: ...                  4   \n",
       "1398  <br><br> Karen: I passed!!!!! <br><br> Simon: ...                  4   \n",
       "1399  <br><br> Karen: I passed!!!!! <br><br> Simon: ...                  4   \n",
       "\n",
       "      consistency_results  relevance_results fluency_results  \\\n",
       "0                       5                  4               5   \n",
       "1                       2                  2               3   \n",
       "2                       5                  1               5   \n",
       "3                       1                  1               5   \n",
       "4                       1                  1               3   \n",
       "...                   ...                ...             ...   \n",
       "1395                    5                  5               5   \n",
       "1396                    5                  3               5   \n",
       "1397                    5                  4               5   \n",
       "1398                    5                  3               5   \n",
       "1399                    5                  3               5   \n",
       "\n",
       "                                               comments  \n",
       "0                                                   NaN  \n",
       "1     Just takes sentences from the original dialogu...  \n",
       "2     Does not capture some of the facts that are in...  \n",
       "3     Not true, doesnt capture any of the importantt...  \n",
       "4     Not true fact, doesnt capture other important ...  \n",
       "...                                                 ...  \n",
       "1395                                      Any comments?  \n",
       "1396                                      Any comments?  \n",
       "1397                                      Any comments?  \n",
       "1398                                      Any comments?  \n",
       "1399                                      Any comments?  \n",
       "\n",
       "[1400 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mojca"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13bd8270",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b361266-8eb5-4ce8-af11-c919cb262437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our data\n",
    "ann1 = pd.read_csv(f'data/saved_df_ann1.csv', delimiter=';')\n",
    "ann2 = pd.read_csv(f'data/saved_df_ann2.csv', delimiter=';')\n",
    "ann3 = pd.read_csv(f'data/saved_df_ann3.csv', delimiter=';')\n",
    "\n",
    "# original data\n",
    "fname = 'data/human_judgment.jsonl'\n",
    "data = [] #NEWstart\n",
    "with open(fname, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line.rstrip('\\n|\\r')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fab5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform original data to match our data\n",
    "original_annotator_scores= []\n",
    "\n",
    "# a row in the data: id, dialogue, summary, annotations, model_id\n",
    "# loop through annotator and each dimension \n",
    "for annotator in [0,1,2]:  \n",
    "    scores = []  \n",
    "    for type in ['consistency', 'coherence', 'fluency', 'relevance']:\n",
    "        list_annotations=[]\n",
    "        # store all annotations for an annotator \n",
    "        for row in data:\n",
    "            annotations = row.get('annotations')\n",
    "            list_annotations.append(annotations[annotator])\n",
    "        dimension_list=[]\n",
    "        # \n",
    "        for dimensions in list_annotations:\n",
    "            dimension=dimensions.get(type.lower())\n",
    "            dimension_list.append(dimension)\n",
    "        scores.append(dimension_list)\n",
    "    original_annotator_scores.append(scores)\n",
    "\n",
    "orig_ann1 = pd.DataFrame(zip(original_annotator_scores[0][0], original_annotator_scores[0][1], original_annotator_scores[0][2], original_annotator_scores[0][3]), \n",
    "        columns=['consistency_results', 'coherence_results', 'fluency_results', 'relevance_results'])\n",
    "\n",
    "orig_ann2 = pd.DataFrame(zip(original_annotator_scores[1][0], original_annotator_scores[1][1], original_annotator_scores[1][2], original_annotator_scores[1][3]), \n",
    "        columns=['consistency_results', 'coherence_results', 'fluency_results', 'relevance_results'])\n",
    "\n",
    "orig_ann3 = pd.DataFrame(zip(original_annotator_scores[2][0], original_annotator_scores[2][1], original_annotator_scores[2][2], original_annotator_scores[2][3]), \n",
    "        columns=['consistency_results', 'coherence_results', 'fluency_results', 'relevance_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78e3d7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(orig_ann2['coherence_results']) == list(orig_ann3['coherence_results'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cbdd348",
   "metadata": {},
   "source": [
    "# set up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "597d9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusted functions for our input data\n",
    "def chonker(seq, size):\n",
    "    return (seq[pos:pos+size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def filter_noise_scores(s_1, s_2, s_3):\n",
    "    '''\n",
    "        filter noise ratings of human and give the average value\n",
    "        return numpy.array (100, 14)\n",
    "    '''\n",
    "    res = np.zeros((100, 14))\n",
    "    for i, (r_1, r_2, r_3) in enumerate(zip(s_1, s_2, s_3)):\n",
    "        for j, (a, b, c) in enumerate(zip(r_1, r_2, r_3)):\n",
    "            if a == b and a != c:\n",
    "                res[i,j] = a\n",
    "            elif a == c and a != b:\n",
    "                res[i,j] = c\n",
    "            elif b == c and a != b:\n",
    "                res[i,j] = b\n",
    "            else:\n",
    "                res[i,j] = (a + b + c) / 3\n",
    "    return res\n",
    "\n",
    "def no_noise_lists(s_1, s_2, s_3):\n",
    "    '''\n",
    "        filter noise ratings of human\n",
    "    '''\n",
    "    new_ann1 = []\n",
    "    new_ann2 = []\n",
    "    new_ann3 = []\n",
    "    nans=0\n",
    "    for (r_1, r_2, r_3) in zip(s_1, s_2, s_3):\n",
    "        for (a, b, c) in zip(r_1, r_2, r_3):\n",
    "            if a == b and a != c:\n",
    "                new_ann1.append(a)\n",
    "                new_ann2.append(b)\n",
    "                new_ann3.append(np.nan)\n",
    "                nans+=1\n",
    "            elif a == c and a != b:\n",
    "                new_ann1.append(a)\n",
    "                new_ann2.append(np.nan)\n",
    "                new_ann3.append(c)\n",
    "                nans+=1\n",
    "            elif b == c and a != b:\n",
    "                new_ann1.append(np.nan)\n",
    "                new_ann2.append(b)\n",
    "                new_ann3.append(c)\n",
    "                nans+=1\n",
    "            else:\n",
    "                new_ann1.append(a)\n",
    "                new_ann2.append(b)\n",
    "                new_ann3.append(c)\n",
    "\n",
    "    print(4200-nans)\n",
    "    return new_ann1, new_ann2, new_ann3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b59dbb84",
   "metadata": {},
   "source": [
    "### Set up variables to do IAA and correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12a31fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our annotations\n",
    "# transform the list of evaluation values into: [[n*14]*100]\n",
    "coherence_ann1 = chonker(list(ann1['coherence_results']), 14)\n",
    "coherence_ann2 = chonker(list(ann2['coherence_results']), 14)\n",
    "coherence_ann3 = chonker(list(ann3['coherence_results']), 14)\n",
    "\n",
    "consistency_ann1 = chonker(list(ann1['consistency_results']), 14)\n",
    "consistency_ann2 = chonker(list(ann2['consistency_results']), 14)\n",
    "consistency_ann3 = chonker(list(ann3['consistency_results']), 14)\n",
    "\n",
    "fluency_ann1 = chonker(list(ann1['fluency_results']), 14)\n",
    "fluency_ann2 = chonker(list(ann2['fluency_results']), 14)\n",
    "fluency_ann3 = chonker(list(ann3['fluency_results']), 14)\n",
    "\n",
    "relevance_ann1 = chonker(list(ann1['relevance_results']), 14)\n",
    "relevance_ann2 = chonker(list(ann2['relevance_results']), 14)\n",
    "relevance_ann3 = chonker(list(ann3['relevance_results']), 14)\n",
    "\n",
    "# Original Annotators\n",
    "# transform the list of evaluation values into: [[n*14]*100]\n",
    "coherence_orig_ann1 = chonker(list(orig_ann1['coherence_results']), 14)\n",
    "coherence_orig_ann2 = chonker(list(orig_ann2['coherence_results']), 14)\n",
    "coherence_orig_ann3 = chonker(list(orig_ann3['coherence_results']), 14)\n",
    "\n",
    "consistency_orig_ann1 = chonker(list(orig_ann1['consistency_results']), 14)\n",
    "consistency_orig_ann2 = chonker(list(orig_ann2['consistency_results']), 14)\n",
    "consistency_orig_ann3 = chonker(list(orig_ann3['consistency_results']), 14)\n",
    "\n",
    "fluency_orig_ann1 = chonker(list(orig_ann1['fluency_results']), 14)\n",
    "fluency_orig_ann2 = chonker(list(orig_ann2['fluency_results']), 14)\n",
    "fluency_orig_ann3 = chonker(list(orig_ann3['fluency_results']), 14)\n",
    "\n",
    "relevance_orig_ann1 = chonker(list(orig_ann1['relevance_results']), 14)\n",
    "relevance_orig_ann2 = chonker(list(orig_ann2['relevance_results']), 14)\n",
    "relevance_orig_ann3 = chonker(list(orig_ann3['relevance_results']), 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad5ec825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3161\n",
      "3360\n",
      "3050\n",
      "3439\n"
     ]
    }
   ],
   "source": [
    "# noise filtering for IAA check\n",
    "orig_coherence_nonoise1, orig_coherence_nonoise2, orig_coherence_nonoise3 = no_noise_lists(coherence_orig_ann1, coherence_orig_ann2, coherence_orig_ann3)\n",
    "orig_consistency_nonoise1, orig_consistency_nonoise2, orig_consistency_nonoise3 = no_noise_lists(consistency_orig_ann1, consistency_orig_ann2, consistency_orig_ann3)\n",
    "orig_fluency_nonoise1, orig_fluency_nonoise2, orig_fluency_nonoise3 = no_noise_lists(fluency_orig_ann1, fluency_orig_ann2, fluency_orig_ann3)\n",
    "orig_relevance_nonoise1, orig_relevance_nonoise2, orig_relevance_nonoise3 = no_noise_lists(relevance_orig_ann1, relevance_orig_ann2, relevance_orig_ann3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca6c4b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3607\n",
      "3754\n",
      "3625\n",
      "3394\n"
     ]
    }
   ],
   "source": [
    "coherence_nonoise1, coherence_nonoise2, coherence_nonoise3 = no_noise_lists(coherence_ann1, coherence_ann2, coherence_ann3)\n",
    "consistency_nonoise1,consistency_nonoise2,consistency_nonoise3 = no_noise_lists(consistency_ann1, consistency_ann2, consistency_ann3)\n",
    "fluency_nonoise1, fluency_nonoise2,fluency_nonoise3 = no_noise_lists(fluency_ann1, fluency_ann2, fluency_ann3)\n",
    "relevance_nonoise1,relevance_nonoise2,relevance_nonoise3 = no_noise_lists(relevance_ann1, relevance_ann2, relevance_ann3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16a5116d",
   "metadata": {},
   "source": [
    "# calculations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc9e20b0",
   "metadata": {},
   "source": [
    "### IAA calculations\n",
    "using krippendorff's alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc44a257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original IAA scores:\n",
      "Coherence: 0.3785576910327453 \n",
      "Consistency: 0.492762621233651 \n",
      "Fluency: 0.13361325787541334 \n",
      "Relevance: 0.38671951755027045\n"
     ]
    }
   ],
   "source": [
    "# Original IAA\n",
    "coherence_IAA = krippendorff.alpha(reliability_data=[list(orig_ann1['coherence_results']),list(orig_ann2['coherence_results']),list(orig_ann3['coherence_results'])], level_of_measurement=\"interval\")\n",
    "fluency_IAA = krippendorff.alpha(reliability_data=[list(orig_ann1['fluency_results']),list(orig_ann2['fluency_results']),list(orig_ann3['fluency_results'])],level_of_measurement=\"interval\")\n",
    "consistency_IAA = krippendorff.alpha(reliability_data=[list(orig_ann1['consistency_results']),list(orig_ann2['consistency_results']),list(orig_ann3['consistency_results'])],level_of_measurement=\"interval\")\n",
    "relevance_IAA = krippendorff.alpha(reliability_data=[list(orig_ann1['relevance_results']),list(orig_ann2['relevance_results']),list(orig_ann3['relevance_results'])],level_of_measurement=\"interval\")\n",
    "\n",
    "print(f'Original IAA scores:\\nCoherence: {coherence_IAA} \\nConsistency: {consistency_IAA} \\nFluency: {fluency_IAA} \\nRelevance: {relevance_IAA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36d58658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original IAA scores (cleaned):\n",
      "Coherence: 0.7564020052749023 \n",
      "Consistency: 0.6709247287723659 \n",
      "Fluency: 0.6781873766563293 \n",
      "Relevance: 0.5620838662718799\n"
     ]
    }
   ],
   "source": [
    "coherence_IAA = krippendorff.alpha(reliability_data=[orig_coherence_nonoise1, orig_coherence_nonoise2, orig_coherence_nonoise3], level_of_measurement=\"interval\")\n",
    "fluency_IAA = krippendorff.alpha(reliability_data=[orig_fluency_nonoise1, orig_fluency_nonoise2, orig_fluency_nonoise3],level_of_measurement=\"interval\")\n",
    "consistency_IAA = krippendorff.alpha(reliability_data=[orig_consistency_nonoise1, orig_consistency_nonoise2, orig_consistency_nonoise3],level_of_measurement=\"interval\")\n",
    "relevance_IAA = krippendorff.alpha(reliability_data=[orig_relevance_nonoise1, orig_relevance_nonoise2, orig_relevance_nonoise3],level_of_measurement=\"interval\")\n",
    "\n",
    "print(f'Original IAA scores (cleaned):\\nCoherence: {coherence_IAA} \\nConsistency: {consistency_IAA} \\nFluency: {fluency_IAA} \\nRelevance: {relevance_IAA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efab3a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our IAA scores:\n",
      "Coherence: 0.6074598852525589 \n",
      "Consistency: 0.7938139086383895 \n",
      "Fluency: 0.5233497800176004 \n",
      "Relevance: 0.5159398644189812\n"
     ]
    }
   ],
   "source": [
    "# Our IAA\n",
    "coherence_IAA = krippendorff.alpha(reliability_data=[list(ann1['coherence_results']),list(ann2['coherence_results']),list(ann3['coherence_results'])], level_of_measurement=\"interval\")\n",
    "fluency_IAA = krippendorff.alpha(reliability_data=[list(ann1['fluency_results']),list(ann2['fluency_results']),list(ann3['fluency_results'])],level_of_measurement=\"interval\")\n",
    "consistency_IAA = krippendorff.alpha(reliability_data=[list(ann1['consistency_results']),list(ann2['consistency_results']),list(ann3['consistency_results'])],level_of_measurement=\"interval\")\n",
    "relevance_IAA = krippendorff.alpha(reliability_data=[list(ann1['relevance_results']),list(ann2['relevance_results']),list(ann3['relevance_results'])],level_of_measurement=\"interval\")\n",
    "\n",
    "print(f'Our IAA scores:\\nCoherence: {coherence_IAA} \\nConsistency: {consistency_IAA} \\nFluency: {fluency_IAA} \\nRelevance: {relevance_IAA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e37d9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our IAA scores (cleaned):\n",
      "Coherence: 0.7780447258554797 \n",
      "Consistency: 0.9227800328928509 \n",
      "Fluency: 0.76903271937251 \n",
      "Relevance: 0.7160557952595286\n"
     ]
    }
   ],
   "source": [
    "coherence_IAA = krippendorff.alpha(reliability_data=[coherence_nonoise1, coherence_nonoise2, coherence_nonoise3], level_of_measurement=\"interval\")\n",
    "fluency_IAA = krippendorff.alpha(reliability_data=[fluency_nonoise1, fluency_nonoise2, fluency_nonoise3],level_of_measurement=\"interval\")\n",
    "consistency_IAA = krippendorff.alpha(reliability_data=[consistency_nonoise1, consistency_nonoise2, consistency_nonoise3],level_of_measurement=\"interval\")\n",
    "relevance_IAA = krippendorff.alpha(reliability_data=[relevance_nonoise1, relevance_nonoise2, relevance_nonoise3],level_of_measurement=\"interval\")\n",
    "\n",
    "print(f'Our IAA scores (cleaned):\\nCoherence: {coherence_IAA} \\nConsistency: {consistency_IAA} \\nFluency: {fluency_IAA} \\nRelevance: {relevance_IAA}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adba78ef",
   "metadata": {},
   "source": [
    "### Correlation between our and original results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9a40351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each dimension filer out the noise and take the average\n",
    "# our results\n",
    "coherence_filtered = filter_noise_scores(coherence_ann1, coherence_ann2, coherence_ann3)\n",
    "consistency_filtered = filter_noise_scores(consistency_ann1, consistency_ann2, consistency_ann3)\n",
    "fluency_filtered = filter_noise_scores(fluency_ann1, fluency_ann2, fluency_ann3)\n",
    "relevance_filtered = filter_noise_scores(relevance_ann1, relevance_ann2, relevance_ann3) \n",
    "\n",
    "# original results\n",
    "orig_coherence_filtered = filter_noise_scores(coherence_orig_ann1, coherence_orig_ann2, coherence_orig_ann3)\n",
    "orig_consistency_filtered = filter_noise_scores(consistency_orig_ann1, consistency_orig_ann2, consistency_orig_ann3)\n",
    "orig_fluency_filtered = filter_noise_scores(fluency_orig_ann1, fluency_orig_ann2, fluency_orig_ann3)\n",
    "orig_relevance_filtered = filter_noise_scores(relevance_orig_ann1, relevance_orig_ann2, relevance_orig_ann3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "709b0901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAA scores between filtered results:\n",
      "Coherence: 0.37876580164604223 \n",
      "Consistency: 0.5209832222422306 \n",
      "Fluency: 0.6828214886452186 \n",
      "Relevance: 0.6492179949103607\n"
     ]
    }
   ],
   "source": [
    "# Original IAA\n",
    "coherence_agreement = krippendorff.alpha(reliability_data=[list(itertools.chain(*coherence_filtered)), list(itertools.chain(*orig_coherence_filtered))], level_of_measurement=\"interval\")\n",
    "consistency_agreement = krippendorff.alpha(reliability_data=[list(itertools.chain(*consistency_filtered)), list(itertools.chain(*orig_consistency_filtered))], level_of_measurement=\"interval\")\n",
    "fluency_agreement = krippendorff.alpha(reliability_data=[list(itertools.chain(*fluency_filtered)), list(itertools.chain(*orig_fluency_filtered))], level_of_measurement=\"interval\")\n",
    "relevance_agreement = krippendorff.alpha(reliability_data=[list(itertools.chain(*relevance_filtered)), list(itertools.chain(*orig_relevance_filtered))], level_of_measurement=\"interval\")\n",
    "\n",
    "print(f'IAA scores between filtered results:\\nCoherence: {coherence_agreement} \\nConsistency: {fluency_agreement} \\nFluency: {consistency_agreement} \\nRelevance: {relevance_agreement}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98e7fe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence correlation [[1.         0.41675892]\n",
      " [0.41675892 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "list_coh_fil = list(itertools.chain(*coherence_filtered))\n",
    "list_coh_fil_orig = list(itertools.chain(*orig_coherence_filtered))\n",
    "print('Coherence correlation', np.corrcoef(list_coh_fil, list_coh_fil_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e61d6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency correlation [[1.         0.76980152]\n",
      " [0.76980152 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "list_con_fil = list(itertools.chain(*consistency_filtered))\n",
    "list_con_fil_orig = list(itertools.chain(*orig_consistency_filtered))\n",
    "print('Consistency correlation', np.corrcoef(list_con_fil, list_con_fil_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b70f10c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluency correlation [[1.         0.54568637]\n",
      " [0.54568637 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "list_flu_fil = list(itertools.chain(*fluency_filtered))\n",
    "list_flu_fil_orig = list(itertools.chain(*orig_fluency_filtered))\n",
    "print('Fluency correlation', np.corrcoef(list_flu_fil, list_flu_fil_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10e98edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance correlation [[1.         0.68499235]\n",
      " [0.68499235 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "list_rel_fil = list(itertools.chain(*relevance_filtered))\n",
    "list_rel_fil_orig = list(itertools.chain(*orig_relevance_filtered))\n",
    "print('Relevance correlation', np.corrcoef(list_rel_fil, list_rel_fil_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701176c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feqaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c178736e6233be626511e8d858d9024f4e9417be1ca81cc2192e74cd768095c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
